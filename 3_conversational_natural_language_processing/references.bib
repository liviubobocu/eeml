
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{ouyang2022instructgpt,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@article{schulman2017ppo,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{rafailov2023dpo,
  title={Direct Preference Optimization: Your language model is secretly a reward model},
  author={Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and others},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@article{sutton2024rlsf,
  title={RLSF: Reinforcement learning from self-feedback for improved reasoning in LLMs},
  author={Sutton, Matthew and van Niekerk, Carel and Vukovic, Renato and others},
  journal={arXiv preprint arXiv:2406.00000},
  year={2024}
}

@article{yuan2024srlm,
  title={Self-Rewarding Language Models},
  author={Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and others},
  journal={arXiv preprint arXiv:2401.10020},
  year={2024}
}

@inproceedings{budzianowski2018multiwoz,
  title={MultiWOZ--A large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling},
  author={Budzianowski, Pawe{\l} and Wen, Tsung-Hsien and Tseng, Bo-Hsiang and others},
  booktitle={Proceedings of the 2018 EMNLP},
  year={2018}
}

@article{li2023emowoz,
  title={EmoWOZ: A Large-Scale Emotion-Aware Dataset for Task-Oriented Dialogue},
  author={Li, Mengdi and Zhang, Yihuai and Du, Huan and others},
  journal={arXiv preprint arXiv:2303.13364},
  year={2023}
}

@inproceedings{zhu2020convlab2,
  title={ConvLab-2: An open-source toolkit for building, evaluating, and diagnosing dialogue systems},
  author={Zhu, Qi and Zhang, Zheng and Fang, Yan and others},
  booktitle={Proceedings of ACL 2020 (System Demonstrations)},
  year={2020}
}

@article{zhu2022convlab3,
  title={ConvLab-3: A flexible dialogue system toolkit based on a unified data format},
  author={Zhu, Qi and Geishauser, Christian and van Niekerk, Hsien-Chin Lin and others},
  journal={arXiv preprint arXiv:2211.17148},
  year={2022}
}

@article{geishauser2022ddpt,
  title={Dynamic dialogue policy transformer for continual reinforcement learning},
  author={Geishauser, Christian and van Niekerk, Carel and Lubis, Nurul and others},
  journal={arXiv preprint arXiv:2204.05928},
  year={2022}
}

@article{rolnick2019clear,
  title={Experience replay for continual learning},
  author={Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and others},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{dhuliawala2023cove,
  title={Chain-of-Verification reduces hallucination in large language models},
  author={Dhuliawala, Shehzaad and Komeili, Mojtaba and Xu, Jing and others},
  journal={arXiv preprint arXiv:2309.11495},
  year={2023}
}

@misc{ft2025hallucinations,
  title={The 'hallucinations' that haunt AI: why chatbots struggle to tell the truth},
  author={Financial Times},
  note={Published July 22, 2025},
  year={2025},
  howpublished={\url{https://www.ft.com/...}}
}

@article{junior2025lid,
  title={Local Intrinsic Dimensions of Contextual Language Models},
  author={Junior, Pedro et al.},
  journal={arXiv preprint arXiv:2506.01034},
  year={2025}
}

@inproceedings{tempczyk2022lid,
  title={Local Intrinsic Dimension Estimation Using Approximate Likelihood},
  author={Tempczyk, Piotr and Michaluk, Rafa{\l} and Garncarek, {\L}ukasz and others},
  booktitle={Proceedings of ICML 2022},
  year={2022}
}

@article{gulcehre2023rest,
  title={Reinforced self-training for language modeling},
  author={G{\"u}l{\c{c}}ehre, {\c{C}}a{\u{g}}lar and Paine, Tom Le and Srinivasan, Srivatsan and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023}
}
